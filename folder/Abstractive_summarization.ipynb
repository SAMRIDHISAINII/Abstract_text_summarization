{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Abstractive_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "coursera": {
      "schema_names": [
        "NLPC4-2"
      ]
    },
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGHtb_W9zEBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9966080a-4213-4715-fdaa-7bd924fdd90a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2Jv2kREHSn5",
        "outputId": "0abcbae2-28a5-429c-ab1c-1dfded2c15f9"
      },
      "source": [
        "!pip -q install trax"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 522kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 11.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4MB 17.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 51.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 48.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 55.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 53.9MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CChWzW-rEHVb"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=70)\n",
        "\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.fastmath import numpy as jnp\n",
        "\n",
        "# to print the entire np array\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEL2rvaHRWP4"
      },
      "source": [
        "<a name='1'></a>\n",
        "## Part 1: Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFMU8kTTVji3"
      },
      "source": [
        "news = pd.read_excel('/content/drive/MyDrive/Summarization/data/news.xlsx')\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Qsk9bDw-WenX",
        "outputId": "bf67a82d-f529-4154-fab8-a817e2467fb3"
      },
      "source": [
        "news.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)\r\n",
        "news.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Short</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
              "      <td>The CBI on Saturday booked four former officia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
              "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
              "      <td>At least three people were killed, including a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why has Reliance been barred from trading in f...</td>\n",
              "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Was stopped from entering my own studio at Tim...</td>\n",
              "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline                                              Short\n",
              "0  4 ex-bank officials booked for cheating bank o...  The CBI on Saturday booked four former officia...\n",
              "1     Supreme Court to go paperless in 6 months: CJI  Chief Justice JS Khehar has said the Supreme C...\n",
              "2  At least 3 killed, 30 injured in blast in Sylh...  At least three people were killed, including a...\n",
              "3  Why has Reliance been barred from trading in f...  Mukesh Ambani-led Reliance Industries (RIL) wa...\n",
              "4  Was stopped from entering my own studio at Tim...  TV news anchor Arnab Goswami has said he was t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKVDgmLMWvzV",
        "outputId": "a63d1485-760e-40e5-9713-a8439ff3cc1b"
      },
      "source": [
        "news.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMuKdaaWWyH_"
      },
      "source": [
        "document = news['Short']\r\n",
        "summary = news['Headline']\r\n",
        "def create_data_stream(document, summary):\r\n",
        "  for doc, sum in zip(document, summary):\r\n",
        "    yield doc, sum\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYMKX0T-Zry_",
        "outputId": "3ac58cb9-9fc4-45be-f467-ea90175d89b7"
      },
      "source": [
        "portion = 0.96\r\n",
        "index_portion = int(len(document) * 0.96)\r\n",
        "print(index_portion)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJVRUJJIXiV8"
      },
      "source": [
        "train_document = news['Short'][:52899]\r\n",
        "train_summary = news['Headline'][:52899]\r\n",
        "eval_document = news['Short'][52899:]\r\n",
        "eval_summary = news['Headline'][52899:]\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtzhCSeDeIR6"
      },
      "source": [
        "train_document = [bytes(doc, 'utf-8') for doc in train_document]\r\n",
        "train_summary = [bytes(summ, 'utf-8') for summ in train_summary]\r\n",
        "eval_document = [bytes(doc, 'utf-8') for doc in eval_document]\r\n",
        "eval_summary = [bytes(summ, 'utf-8') for summ in eval_summary]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8cKGidFXiYu"
      },
      "source": [
        "train_data_stream = create_data_stream(train_document, train_summary)\r\n",
        "eval_data_stream = create_data_stream(eval_document, eval_summary)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjSPRYcdXicG",
        "outputId": "d37bc0a9-cb12-4196-f796-0ba3839f296b"
      },
      "source": [
        "print(next(train_data_stream))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(b'The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing \\xe2\\x82\\xb9209 crore loss to the state-run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.', b'4 ex-bank officials booked for cheating bank of \\xe2\\x82\\xb9209 crore')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsylIVFZdjK7",
        "outputId": "2c9ae92d-37ee-404d-bc40-a675bf50dce7"
      },
      "source": [
        "print(type(next(train_data_stream)[1]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'bytes'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "forFAdA_FyTT"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "## 1.1 Tokenize & Detokenize helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djTiSLcaNFGa"
      },
      "source": [
        "def tokenize(input_str, EOS=1):\n",
        "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "  \n",
        "    # Use the trax.data.tokenize method. It takes streams and returns streams,\n",
        "    # we get around it by making a 1-element stream with `iter`.\n",
        "    inputs =  next(trax.data.tokenize(iter([input_str]),\n",
        "                                      vocab_dir='/content/drive/MyDrive/Summarization/vocab_dir',\n",
        "                                      vocab_file='summarize32k.subword.subwords'))\n",
        "    \n",
        "    # Mark the end of the sentence with EOS\n",
        "    return list(inputs) + [EOS]\n",
        "\n",
        "def detokenize(integers):\n",
        "    \"\"\"List of ints to str\"\"\"\n",
        "  \n",
        "    s = trax.data.detokenize(integers,\n",
        "                             vocab_dir='/content/drive/MyDrive/Summarization/vocab_dir',\n",
        "                             vocab_file='summarize32k.subword.subwords')\n",
        "    \n",
        "    return wrapper.fill(s)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-250BFJFyTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4779788b-fa14-42ec-c968-8fcf97a00232"
      },
      "source": [
        "# test \n",
        "print(tokenize('why you did that shit to me, man?', EOS=1))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11406, 33, 206, 285, 12803, 320, 156, 2, 157, 3882, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WvhaFbCRWQS"
      },
      "source": [
        "<a name='1.2'></a>\n",
        "\n",
        "## 1.2 Preprocessing for Language Models: Concatenate It!\n",
        "\n",
        "You will use a language model -- Transformer Decoder -- to solve\n",
        "an input-output problem. As you know, language models only predict the next\n",
        "word, they have no notion of inputs. To create a single input suitable for\n",
        "a language model, we concatenate inputs with targets putting a separator\n",
        "in between. We also need to create a mask -- with 0s at inputs and 1s at targets -- so that the model is not penalized for mis-predicting the article and only focuses on the summary. See the preprocess function below for how this is done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4rgPxYSRWQS"
      },
      "source": [
        "# Special tokens\n",
        "SEP = 0 # Padding or separator token\n",
        "EOS = 1 # End of sentence token\n",
        "\n",
        "# Concatenate tokenized inputs and targets using 0 as separator.\n",
        "def preprocess(stream):\n",
        "    for (article, summary) in stream:\n",
        "        joint = np.array(list(article) + [EOS, SEP] + list(summary) + [EOS])\n",
        "        mask = [0] * (len(list(article)) + 2) + [1] * (len(list(summary)) + 1) # Accounting for EOS and SEP\n",
        "        yield joint, joint, np.array(mask)\n",
        "\n",
        "# You can combine a few data preprocessing steps into a pipeline like this.\n",
        "input_pipeline = trax.data.Serial(\n",
        "    # Tokenizes\n",
        "    trax.data.Tokenize(vocab_dir='/content/drive/MyDrive/Summarization/vocab_dir',\n",
        "                       vocab_file='summarize32k.subword.subwords'),\n",
        "    # Uses function defined above\n",
        "    preprocess,\n",
        "    # Filters out examples longer than 2048\n",
        "    trax.data.FilterByLength(2048)\n",
        ")\n",
        "\n",
        "# Apply preprocessing to data streams.\n",
        "train_stream = input_pipeline(train_data_stream)\n",
        "eval_stream = input_pipeline(eval_data_stream)\n",
        "\n",
        "train_input, train_target, train_mask = next(train_stream)\n",
        "\n",
        "assert sum((train_input - train_target)**2) == 0  # They are the same in Language Model (LM)."
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKFoGsUKSa_I",
        "outputId": "93b4b52e-3d4c-4cb1-9458-0b27309424c6"
      },
      "source": [
        "# prints mask, 0s on article, 1s on summary\n",
        "print(f'Single example mask:\\n\\n {train_mask}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single example mask:\n",
            "\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4uHyCkbSuUo",
        "outputId": "f0df4f76-bb0c-4a5e-8f53-e4c7be4b7de4"
      },
      "source": [
        "# prints: [Example][<EOS>][<pad>][Example Summary][<EOS>]\n",
        "print(f'Single example:\\n\\n {detokenize(train_input)}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single example:\n",
            "\n",
            " At least three people were killed, including a policeman, while 30\n",
            "others were wounded on Saturday evening in two explosions in Sylhet,\n",
            "Bangladesh. The explosions were targetted at people and police\n",
            "officials who were witnessing an over 30-hour-long gunfight between\n",
            "extremists and commandos. Earlier on Friday, a man had blown himself\n",
            "up in front of a checkpoint near Dhaka Airport.<EOS><pad>Atleast 3\n",
            "killed, 30 injured in blast in Sylhet, Bangladesh<EOS>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4sDS1WIVaYG"
      },
      "source": [
        "<a name='1.3'></a>\n",
        "\n",
        "## 1.3 Batching with bucketing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqj1NsbERWQX"
      },
      "source": [
        "# Bucketing to create batched generators.\n",
        "\n",
        "# Buckets are defined in terms of boundaries and batch sizes.\n",
        "# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n",
        "# So below, we'll take a batch of 16 sentences of length < 128 , 8 of length < 256,\n",
        "# 4 of length < 512. And so on. \n",
        "boundaries =  [128, 256,  512, 1024]\n",
        "batch_sizes = [16,    8,    4,    2, 1]\n",
        "\n",
        "# Create the streams.\n",
        "train_batch_stream = trax.data.BucketByLength(\n",
        "    boundaries, batch_sizes)(train_stream)\n",
        "\n",
        "eval_batch_stream = trax.data.BucketByLength(\n",
        "    boundaries, batch_sizes)(eval_stream)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6M5OA8QRWQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251a3151-636e-409d-a778-0644644a14d8"
      },
      "source": [
        "# Every execution will result in generation of a different article\n",
        "# Try running this cell multiple times to see how the length of the examples affects the batch size\n",
        "input_batch, _, mask_batch = next(train_batch_stream)\n",
        "\n",
        "# Shape of the input_batch\n",
        "input_batch.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjNOlljxTGuQ",
        "outputId": "62e93f40-6ea9-4098-f9f5-c2242e09a667"
      },
      "source": [
        "# print corresponding integer values\n",
        "print(input_batch[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[21286 12524  5336  7316     6   375  8647  1362 15531     8  3513   197\n",
            "    12  1353 17548    21  1838  7102   132 14418  2432   700  1019    28\n",
            "   104    95 14125  2084   132  8647  1362 21192 23794     8  6576   197\n",
            "    24    34   485     2  3513   197  1398    66    10    32   237 14125\n",
            "   132  6576   197     2    35  4003    25    60   669  9207  1725  1628\n",
            "   620     6  1398  9207  1725    29   132 14418  2432   700   320  2501\n",
            "    28  1198   132  6576   197 21064     3  8073  2084   614  3438  4003\n",
            "  1248  1420   320  2444   105   179   272   809   994  2664    10     1\n",
            "     0  1773    23  8647  1362    46 17548    21  1838  7102   132 14418\n",
            "  2432  3882     1     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq9xxMjQFyTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9077d724-cbab-4414-ef68-826e87ed9b4d"
      },
      "source": [
        "# test linh tinh \n",
        "print(mask_batch[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu05ZwbWTE6P",
        "outputId": "f0a05424-4957-45b0-e470-f32913275d2a"
      },
      "source": [
        "# print the article and its summary\n",
        "print('Article:\\n\\n', detokenize(input_batch[0]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article:\n",
            "\n",
            " Mukesh Ambani-led Reliance Industries (RIL) was barred from trading in\n",
            "futures market for a year over stake sale in Reliance Petroleum (RPL).\n",
            "In 2007, RIL sold 4.1% stake in RPL, but shares were first &#39;short-\n",
            "sold&#39; in futures market to avoid a fall in RPL stocks. Short sale\n",
            "means selling shares with plans to buy them back later at lower\n",
            "prices.<EOS><pad>Whyhas Reliance been barred from trading in futures?<\n",
            "EOS><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
            "pad><pad><pad><pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNFVhgHoncGm"
      },
      "source": [
        "You can see that the data has the following structure:\n",
        "- <span style='color:blue'> [Article] </span> -> `<EOS>` -> `<pad>` -> <span style='color:blue'> [Article Summary] </span> -> `<EOS>` -> (possibly) multiple `<pad>`\n",
        "\n",
        "The loss is taken only on the summary using cross_entropy as loss function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un8NHIRoj-1W"
      },
      "source": [
        "<a name='2'></a>\n",
        "# Part 2: Summarization with transformer\n",
        "\n",
        "\n",
        "<a name='2.1'></a>\n",
        "## 2.1 Dot product attention \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5aQ96frFyTl"
      },
      "source": [
        "<a name='ex01'></a>\n",
        "\n",
        "$$\n",
        "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
        "$$\n",
        "\n",
        "$Q$ - query, \n",
        "$K$ - key, \n",
        "$V$ - values, \n",
        "$M$ - mask, \n",
        "${d_k}$ - depth/dimension of the queries and keys (used for scaling down)\n",
        "\n",
        "You can implement this formula either by `trax` numpy (trax.math.numpy) or regular `numpy` but it is recommended to use `jnp`.\n",
        "\n",
        "Something to take into consideration is that within trax, the masks are tensors of `True/False` values not 0's and $-\\infty$ as in the previous example. Within the graded function don't think of applying the mask by summing up matrices, instead use `jnp.where()` and treat the **mask as a tensor of boolean values with `False` for values that need to be masked and True for the ones that don't.**\n",
        "\n",
        "Also take into account that the real tensors are far more complex than the toy ones you just played with. Because of this avoid using shortened operations such as `@` for dot product or `.T` for transposing. Use `jnp.matmul()` and `jnp.swapaxes()` instead.\n",
        "\n",
        "This is the self-attention block for the transformer decoder.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSauPt0NUl_o"
      },
      "source": [
        "def DotProductAttention(query, key, value, mask):\n",
        "    \"\"\"Dot product self-attention.\n",
        "    Args:\n",
        "        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n",
        "        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n",
        "        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n",
        "        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n",
        "\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by L_k)\n",
        "    \"\"\"\n",
        "\n",
        "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
        "\n",
        "    # Save depth/dimension of the query embedding for scaling down the dot product\n",
        "    depth = query.shape[-1]\n",
        "\n",
        "    # Calculate scaled query key dot product according to formula above\n",
        "    dots = jnp.matmul(query, jnp.swapaxes(key, -1, -2)) / jnp.sqrt(depth)\n",
        "    \n",
        "    # Apply the mask\n",
        "    if mask is not None: # The 'None' in this line does not need to be replaced\n",
        "        dots = jnp.where(mask, dots, jnp.full_like(dots, -1e9))\n",
        "    \n",
        "    # Softmax formula implementation\n",
        "    # Use trax.fastmath.logsumexp of dots to avoid underflow by division by large numbers\n",
        "    # Hint: Last axis should be used and keepdims should be True\n",
        "    # Note: softmax = e^(dots - logsumexp(dots)) = E^dots / sumexp(dots)\n",
        "    logsumexp = trax.fastmath.logsumexp(dots, axis=-1, keepdims=True)\n",
        "\n",
        "    # Take exponential of dots minus logsumexp to get softmax\n",
        "    # Use jnp.exp()\n",
        "    dots = jnp.exp(dots-logsumexp)\n",
        "\n",
        "    # Multiply dots by value to get self-attention\n",
        "    # Use jnp.matmul()\n",
        "    attention = jnp.matmul(dots, value)\n",
        "    \n",
        "    return attention"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y2PSiLVRWQ2"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "\n",
        "## 2.2 Causal Attention\n",
        "\n",
        "Now you are going to implement causal attention: multi-headed attention with a mask to attend only to words that occurred before. \n",
        "\n",
        "<a name='ex02'></a>\n",
        "\n",
        "Implement the following functions that will be needed for Causal Attention:\n",
        "\n",
        "- <span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n",
        "- <span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention.\n",
        "- <span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKf7rUmSFyTn"
      },
      "source": [
        "It is important to know that the following 3 functions would normally be defined within the `CausalAttention` function further below. \n",
        "\n",
        "However this makes these functions harder to test. Because of this, these functions are shown individually using a `closure` (when necessary) that simulates them being inside of the `CausalAttention` function. This is done because they rely on some variables that can be accessed from within `CausalAttention`.\n",
        "\n",
        "### Support Functions\n",
        "\n",
        "<span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n",
        "\n",
        "**For the closures you only have to fill the inner function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL8VTcReFyTo"
      },
      "source": [
        "def compute_attention_heads_closure(n_heads, d_head):\n",
        "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
        "    Args:\n",
        "        d_head (int):  dimensionality of heads.\n",
        "        n_heads (int): number of attention heads.\n",
        "    Returns:\n",
        "        function: compute_attention_heads function\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_attention_heads(x):\n",
        "        \"\"\" Compute the attention heads.\n",
        "        Args:\n",
        "            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size, seqlen, n_heads X d_head).\n",
        "        Returns:\n",
        "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size X n_heads, seqlen, d_head).\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        # Length of the sequence\n",
        "        # Should be size of x's first dimension without counting the batch dim\n",
        "        seqlen = x.shape[1]\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # batch_size, seqlen, n_heads*d_head -> batch_size, seqlen, n_heads, d_head\n",
        "        x = jnp.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
        "        # Transpose x using jnp.transpose()\n",
        "        # batch_size, seqlen, n_heads, d_head -> batch_size, n_heads, seqlen, d_head\n",
        "        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n",
        "        x = jnp.transpose(x, (0, 2, 1, 3))\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # batch_size, n_heads, seqlen, d_head -> batch_size*n_heads, seqlen, d_head\n",
        "        x = jnp.reshape(x, (-1, seqlen, d_head))\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    return compute_attention_heads"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdPCo_kUFyTr"
      },
      "source": [
        "<span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_PnA9a6FyTs"
      },
      "source": [
        "def dot_product_self_attention(q, k, v):\n",
        "    \"\"\" Masked dot product self attention.\n",
        "    Args:\n",
        "        q (jax.interpreters.xla.DeviceArray): queries.\n",
        "        k (jax.interpreters.xla.DeviceArray): keys.\n",
        "        v (jax.interpreters.xla.DeviceArray): values.\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Hint: mask size should be equal to L_q. Remember that q has shape (batch_size, L_q, d)\n",
        "    mask_size = q.shape[-2]\n",
        "\n",
        "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
        "    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n",
        "    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n",
        "    mask = jnp.tril(jnp.ones((1, mask_size, mask_size), dtype=jnp.bool_), k=0)\n",
        "    \n",
        "    return DotProductAttention(q, k, v, mask)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVh7kXSxFyTt"
      },
      "source": [
        "<span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BixVueLvFyTt"
      },
      "source": [
        "def compute_attention_output_closure(n_heads, d_head):\n",
        "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
        "    Args:\n",
        "        d_head (int):  dimensionality of heads.\n",
        "        n_heads (int): number of attention heads.\n",
        "    Returns:\n",
        "        function: compute_attention_output function\n",
        "    \"\"\"\n",
        "    \n",
        "    def compute_attention_output(x):\n",
        "        \"\"\" Compute the attention output.\n",
        "        Args:\n",
        "            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size X n_heads, seqlen, d_head).\n",
        "        Returns:\n",
        "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size, seqlen, n_heads X d_head).\n",
        "        \"\"\"\n",
        "\n",
        "        # Length of the sequence\n",
        "        # Should be size of x's first dimension without counting the batch dim\n",
        "        seqlen = x.shape[1]\n",
        "        # Reshape x using jnp.reshape() to shape (batch_size, n_heads, seqlen, d_head)\n",
        "        x = jnp.reshape(x, (-1, n_heads, seqlen, d_head))\n",
        "        # Transpose x using jnp.transpose() to shape (batch_size, seqlen, n_heads, d_head)\n",
        "        x = jnp.transpose(x, (0, 2, 1, 3))\n",
        "             \n",
        "        # Reshape to allow to concatenate the heads\n",
        "        return jnp.reshape(x, (-1, seqlen, n_heads * d_head))\n",
        "    \n",
        "    return compute_attention_output"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktOmhFFbFyTu"
      },
      "source": [
        "### Causal Attention Function\n",
        "\n",
        "Now it is time for you to put everything together within the `CausalAttention` or Masked multi-head attention function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Adn6DtRWRG"
      },
      "source": [
        "def CausalAttention(d_feature, \n",
        "                    n_heads, \n",
        "                    compute_attention_heads_closure=compute_attention_heads_closure,\n",
        "                    dot_product_self_attention=dot_product_self_attention,\n",
        "                    compute_attention_output_closure=compute_attention_output_closure,\n",
        "                    mode='train'):\n",
        "    \"\"\"Transformer-style multi-headed causal attention.\n",
        "\n",
        "    Args:\n",
        "        d_feature (int):  dimensionality of feature embedding.\n",
        "        n_heads (int): number of attention heads.\n",
        "        compute_attention_heads_closure (function): Closure around compute_attention heads.\n",
        "        dot_product_self_attention (function): dot_product_self_attention function. \n",
        "        compute_attention_output_closure (function): Closure around compute_attention_output. \n",
        "        mode (str): 'train' or 'eval'.\n",
        "\n",
        "    Returns:\n",
        "        trax.layers.combinators.Serial: Multi-headed self-attention model.\n",
        "    \"\"\"\n",
        "    \n",
        "    assert d_feature % n_heads == 0\n",
        "    d_head = d_feature // n_heads\n",
        "   \n",
        "    # HINT: The second argument to tl.Fn() is an uncalled function (without the parentheses)\n",
        "    # Since you are dealing with closures you might need to call the outer \n",
        "    # function with the correct parameters to get the actual uncalled function.\n",
        "    ComputeAttentionHeads = tl.Fn('AttnHeads', compute_attention_heads_closure(n_heads, d_head), n_out=1)\n",
        "        \n",
        "\n",
        "    return tl.Serial(\n",
        "        tl.Branch( # creates three towers for one input, takes activations and creates queries keys and values\n",
        "            [tl.Dense(d_feature), ComputeAttentionHeads], # queries\n",
        "            [tl.Dense(d_feature), ComputeAttentionHeads], # keys\n",
        "            [tl.Dense(d_feature), ComputeAttentionHeads], # values\n",
        "        ),\n",
        "        \n",
        "        tl.Fn('DotProductAttn', dot_product_self_attention, n_out=1), # takes QKV\n",
        "        # HINT: The second argument to tl.Fn() is an uncalled function\n",
        "        # Since you are dealing with closures you might need to call the outer \n",
        "        # function with the correct parameters to get the actual uncalled function.\n",
        "        tl.Fn('AttnOutput', compute_attention_output_closure(n_heads, d_head), n_out=1), # to allow for parallel\n",
        "        tl.Dense(d_feature) # Final dense layer\n",
        "    )\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWwvPRClFyTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870e2701-ee7f-4622-c40c-7df0340010a2"
      },
      "source": [
        "# Take a look at the causal attention model\n",
        "print(CausalAttention(d_feature=512, n_heads=8))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serial[\n",
            "  Branch_out3[\n",
            "    [Dense_512, AttnHeads]\n",
            "    [Dense_512, AttnHeads]\n",
            "    [Dense_512, AttnHeads]\n",
            "  ]\n",
            "  DotProductAttn_in3\n",
            "  AttnOutput\n",
            "  Dense_512\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6zwtPjqRWRJ"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "\n",
        "## 2.3 Transformer decoder block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKOxnRbp1K5U"
      },
      "source": [
        "def DecoderBlock(d_model, d_ff, n_heads,\n",
        "                 dropout, mode, ff_activation):\n",
        "    \"\"\"Returns a list of layers that implements a Transformer decoder block.\n",
        "\n",
        "    The input is an activation tensor.\n",
        "\n",
        "    Args:\n",
        "        d_model (int):  depth of embedding.\n",
        "        d_ff (int): depth of feed-forward layer.\n",
        "        n_heads (int): number of attention heads.\n",
        "        dropout (float): dropout rate (how much to drop out).\n",
        "        mode (str): 'train' or 'eval'.\n",
        "        ff_activation (function): the non-linearity in feed-forward layer.\n",
        "\n",
        "    Returns:\n",
        "        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create masked multi-head attention block using CausalAttention function\n",
        "    causal_attention = CausalAttention( \n",
        "                        d_model,\n",
        "                        n_heads=n_heads,\n",
        "                        mode=mode\n",
        "                        )\n",
        "\n",
        "    # Create feed-forward block (list) with two dense layers with dropout and input normalized\n",
        "    feed_forward = [ \n",
        "        # Normalize layer inputs\n",
        "        tl.LayerNorm(),\n",
        "        # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n",
        "        tl.Dense(d_ff),\n",
        "        # Add activation function passed in as a parameter (you need to call it!)\n",
        "        ff_activation(), # Generally ReLU\n",
        "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "        tl.Dropout(rate=dropout, mode=mode),\n",
        "        # Add second feed forward layer (don't forget to set the correct value for n_units)\n",
        "        tl.Dense(d_model),\n",
        "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "        tl.Dropout(rate=dropout, mode=mode)\n",
        "    ]\n",
        "\n",
        "    # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n",
        "    return [\n",
        "      tl.Residual(\n",
        "          # Normalize layer input\n",
        "          tl.LayerNorm(),\n",
        "          # Add causal attention block previously defined (without parentheses)\n",
        "          causal_attention,\n",
        "          # Add dropout with rate and mode specified\n",
        "          tl.Dropout(rate=dropout, mode=mode)\n",
        "        ),\n",
        "      tl.Residual(\n",
        "          # Add feed forward block (without parentheses)\n",
        "          feed_forward\n",
        "        ),\n",
        "      ]\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj_vr1FiFyTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dceee1d9-42c0-49e1-dcb3-a4b8778181d9"
      },
      "source": [
        "# Take a look at the decoder block\n",
        "print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Serial[\n",
            "  Branch_out2[\n",
            "    None\n",
            "    Serial[\n",
            "      LayerNorm\n",
            "      Serial[\n",
            "        Branch_out3[\n",
            "          [Dense_512, AttnHeads]\n",
            "          [Dense_512, AttnHeads]\n",
            "          [Dense_512, AttnHeads]\n",
            "        ]\n",
            "        DotProductAttn_in3\n",
            "        AttnOutput\n",
            "        Dense_512\n",
            "      ]\n",
            "      Dropout\n",
            "    ]\n",
            "  ]\n",
            "  Add_in2\n",
            "], Serial[\n",
            "  Branch_out2[\n",
            "    None\n",
            "    Serial[\n",
            "      LayerNorm\n",
            "      Dense_2048\n",
            "      Serial[\n",
            "        Relu\n",
            "      ]\n",
            "      Dropout\n",
            "      Dense_512\n",
            "      Dropout\n",
            "    ]\n",
            "  ]\n",
            "  Add_in2\n",
            "]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoFv-nfLRWRN"
      },
      "source": [
        "<a name='2.4'></a>\n",
        "## 2.4 Transformer Language Model\n",
        "  \n",
        "<a name='ex04'></a>\n",
        "\n",
        "Previously you coded the decoder block. Now you will code the transformer language model. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yi4LJO1RWRS"
      },
      "source": [
        "def TransformerLM(vocab_size=33300,\n",
        "                  d_model=512,\n",
        "                  d_ff=2048,\n",
        "                  n_layers=6,\n",
        "                  n_heads=8,\n",
        "                  dropout=0.1,\n",
        "                  max_len=4096,\n",
        "                  mode='train',\n",
        "                  ff_activation=tl.Relu):\n",
        "    \"\"\"Returns a Transformer language model.\n",
        "\n",
        "    The input to the model is a tensor of tokens. (This model uses only the\n",
        "    decoder part of the overall Transformer.)\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): vocab size.\n",
        "        d_model (int):  depth of embedding.\n",
        "        d_ff (int): depth of feed-forward layer.\n",
        "        n_layers (int): number of decoder layers.\n",
        "        n_heads (int): number of attention heads.\n",
        "        dropout (float): dropout rate (how much to drop out).\n",
        "        max_len (int): maximum symbol length for positional encoding.\n",
        "        mode (str): 'train', 'eval' or 'predict', predict mode is for fast inference.\n",
        "        ff_activation (function): the non-linearity in feed-forward layer.\n",
        "\n",
        "    Returns:\n",
        "        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens\n",
        "        to activations over a vocab set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Embedding inputs and positional encoder\n",
        "    positional_encoder = [ \n",
        "        # Add embedding layer of dimension (vocab_size, d_model)\n",
        "        tl.Embedding(vocab_size, d_model),\n",
        "        # Use dropout with rate and mode specified\n",
        "        tl.Dropout(rate=dropout, mode=mode),\n",
        "        # Add positional encoding layer with maximum input length and mode specified\n",
        "        tl.PositionalEncoding(max_len=max_len, mode=mode)]\n",
        "\n",
        "    # Create stack (list) of decoder blocks with n_layers with necessary parameters\n",
        "    decoder_blocks = [ \n",
        "        DecoderBlock(d_model, d_ff, n_heads,\n",
        "                    dropout, mode, ff_activation) for _ in range(n_layers)]\n",
        "\n",
        "    # Create the complete model as written in the figure\n",
        "    return tl.Serial(\n",
        "        # Use teacher forcing (feed output of previous step to current step)\n",
        "        tl.ShiftRight(mode=mode), # Specify the mode!\n",
        "        # Add positional encoder\n",
        "        positional_encoder,\n",
        "        # Add decoder blocks\n",
        "        decoder_blocks,\n",
        "        # Normalize layer\n",
        "        tl.LayerNorm(),\n",
        "\n",
        "        # Add dense layer of vocab_size (since need to select a word to translate to)\n",
        "        # (a.k.a., logits layer. Note: activation already set by ff_activation)\n",
        "        tl.Dense(vocab_size),\n",
        "        # Get probabilities with Logsoftmax\n",
        "        tl.LogSoftmax(),\n",
        "    )\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn7wknlkFyT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8654ad-28f9-4370-c180-d47284f593e9"
      },
      "source": [
        "# Take a look at the Transformer\n",
        "print(TransformerLM(n_layers=1))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serial[\n",
            "  Serial[\n",
            "    ShiftRight(1)\n",
            "  ]\n",
            "  Embedding_33300_512\n",
            "  Dropout\n",
            "  PositionalEncoding\n",
            "  Serial[\n",
            "    Branch_out2[\n",
            "      None\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Serial[\n",
            "          Branch_out3[\n",
            "            [Dense_512, AttnHeads]\n",
            "            [Dense_512, AttnHeads]\n",
            "            [Dense_512, AttnHeads]\n",
            "          ]\n",
            "          DotProductAttn_in3\n",
            "          AttnOutput\n",
            "          Dense_512\n",
            "        ]\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    Add_in2\n",
            "  ]\n",
            "  Serial[\n",
            "    Branch_out2[\n",
            "      None\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Serial[\n",
            "          Relu\n",
            "        ]\n",
            "        Dropout\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    Add_in2\n",
            "  ]\n",
            "  LayerNorm\n",
            "  Dense_33300\n",
            "  LogSoftmax\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRRKnoAdvmJ7"
      },
      "source": [
        "<a name='3'></a>\n",
        "# Part 3: Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1lkVebQRWRV"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "### 3.1 Training the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM2gpu4xvjtX"
      },
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "\n",
        "def training_loop(TransformerLM, train_gen, eval_gen, output_dir):\n",
        "    '''\n",
        "    Input:\n",
        "        TransformerLM (trax.layers.combinators.Serial): The model you are building.\n",
        "        train_gen (generator): Training stream of data.\n",
        "        eval_gen (generator): Evaluation stream of data.\n",
        "        output_dir (str): folder to save your file.\n",
        "        \n",
        "    Returns:\n",
        "        trax.supervised.training.Loop: Training loop.\n",
        "    '''\n",
        "    output_dir = os.path.expanduser(output_dir)  # trainer is an object\n",
        "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps=1000, max_value=0.01)\n",
        "    \n",
        "    train_task = training.TrainTask( \n",
        "      labeled_data=train_gen, # The training generator\n",
        "      loss_layer=tl.WeightedCategoryCrossEntropy(), # Loss function \n",
        "      optimizer=trax.optimizers.Adam(0.01), # Optimizer (Don't forget to set LR to 0.01)\n",
        "      lr_schedule=lr_schedule,\n",
        "      n_steps_per_checkpoint=100\n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask( \n",
        "      labeled_data=eval_gen, # The evaluation generator\n",
        "      metrics=[tl.WeightedCategoryCrossEntropy(), tl.WeightedCategoryAccuracy()] # CrossEntropyLoss and Accuracy\n",
        "    )\n",
        "\n",
        "    loop = training.Loop(TransformerLM(d_model=512,\n",
        "                                       d_ff=2048,\n",
        "                                       n_layers=6,\n",
        "                                       n_heads=8,\n",
        "                                       mode='train'),\n",
        "                         train_task,\n",
        "                         eval_tasks=[eval_task],\n",
        "                         output_dir=output_dir)\n",
        "    \n",
        "    return loop"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT6-N1gLFyT3"
      },
      "source": [
        "Notice that the model will be trained for only 10 steps. \n",
        "\n",
        "Even with this constraint the model with the original default arguments took a very long time to finish. Because of this some parameters are changed when defining the model that is fed into the training loop in the function above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BFRBTwSqRWRZ",
        "outputId": "66f951ce-9daa-4ba5-87df-c29f9d6486f1"
      },
      "source": [
        "!rm -f /content/drive/MyDrive/Summarization/models/model.pkl.gz\n",
        "loop = training_loop(TransformerLM, train_batch_stream, eval_batch_stream, output_dir='/content/drive/MyDrive/Summarization/models')\n",
        "loop.run(10000)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 55144980\n",
            "Step      1: Ran 1 train steps in 43.74 secs\n",
            "Step      1: train WeightedCategoryCrossEntropy |  10.45221424\n",
            "Step      1: eval  WeightedCategoryCrossEntropy |  10.42385483\n",
            "Step      1: eval      WeightedCategoryAccuracy |  0.00000000\n",
            "\n",
            "Step    100: Ran 99 train steps in 57.42 secs\n",
            "Step    100: train WeightedCategoryCrossEntropy |  8.28092480\n",
            "Step    100: eval  WeightedCategoryCrossEntropy |  7.64686680\n",
            "Step    100: eval      WeightedCategoryAccuracy |  0.07547170\n",
            "\n",
            "Step    200: Ran 100 train steps in 43.65 secs\n",
            "Step    200: train WeightedCategoryCrossEntropy |  7.48571825\n",
            "Step    200: eval  WeightedCategoryCrossEntropy |  7.66580725\n",
            "Step    200: eval      WeightedCategoryAccuracy |  0.02955665\n",
            "\n",
            "Step    300: Ran 100 train steps in 44.39 secs\n",
            "Step    300: train WeightedCategoryCrossEntropy |  7.35748720\n",
            "Step    300: eval  WeightedCategoryCrossEntropy |  8.06264877\n",
            "Step    300: eval      WeightedCategoryAccuracy |  0.07943925\n",
            "\n",
            "Step    400: Ran 100 train steps in 44.78 secs\n",
            "Step    400: train WeightedCategoryCrossEntropy |  7.11905670\n",
            "Step    400: eval  WeightedCategoryCrossEntropy |  7.61479425\n",
            "Step    400: eval      WeightedCategoryAccuracy |  0.09313726\n",
            "\n",
            "Step    500: Ran 100 train steps in 45.15 secs\n",
            "Step    500: train WeightedCategoryCrossEntropy |  7.09017372\n",
            "Step    500: eval  WeightedCategoryCrossEntropy |  7.61404467\n",
            "Step    500: eval      WeightedCategoryAccuracy |  0.09693877\n",
            "\n",
            "Step    600: Ran 100 train steps in 45.06 secs\n",
            "Step    600: train WeightedCategoryCrossEntropy |  7.01059675\n",
            "Step    600: eval  WeightedCategoryCrossEntropy |  7.48128080\n",
            "Step    600: eval      WeightedCategoryAccuracy |  0.10695188\n",
            "\n",
            "Step    700: Ran 100 train steps in 44.80 secs\n",
            "Step    700: train WeightedCategoryCrossEntropy |  7.00949001\n",
            "Step    700: eval  WeightedCategoryCrossEntropy |  7.29006958\n",
            "Step    700: eval      WeightedCategoryAccuracy |  0.10552764\n",
            "\n",
            "Step    800: Ran 100 train steps in 45.26 secs\n",
            "Step    800: train WeightedCategoryCrossEntropy |  7.05646181\n",
            "Step    800: eval  WeightedCategoryCrossEntropy |  7.32770681\n",
            "Step    800: eval      WeightedCategoryAccuracy |  0.10576923\n",
            "\n",
            "Step    900: Ran 100 train steps in 46.22 secs\n",
            "Step    900: train WeightedCategoryCrossEntropy |  6.98472834\n",
            "Step    900: eval  WeightedCategoryCrossEntropy |  7.10430288\n",
            "Step    900: eval      WeightedCategoryAccuracy |  0.11627907\n",
            "\n",
            "Step   1000: Ran 100 train steps in 44.22 secs\n",
            "Step   1000: train WeightedCategoryCrossEntropy |  7.00283861\n",
            "Step   1000: eval  WeightedCategoryCrossEntropy |  7.55096865\n",
            "Step   1000: eval      WeightedCategoryAccuracy |  0.09836065\n",
            "\n",
            "Step   1100: Ran 100 train steps in 44.14 secs\n",
            "Step   1100: train WeightedCategoryCrossEntropy |  6.93269014\n",
            "Step   1100: eval  WeightedCategoryCrossEntropy |  7.45935488\n",
            "Step   1100: eval      WeightedCategoryAccuracy |  0.08450704\n",
            "\n",
            "Step   1200: Ran 100 train steps in 46.92 secs\n",
            "Step   1200: train WeightedCategoryCrossEntropy |  6.97282505\n",
            "Step   1200: eval  WeightedCategoryCrossEntropy |  7.88233042\n",
            "Step   1200: eval      WeightedCategoryAccuracy |  0.10204081\n",
            "\n",
            "Step   1300: Ran 100 train steps in 44.23 secs\n",
            "Step   1300: train WeightedCategoryCrossEntropy |  7.02917242\n",
            "Step   1300: eval  WeightedCategoryCrossEntropy |  7.44112158\n",
            "Step   1300: eval      WeightedCategoryAccuracy |  0.09359606\n",
            "\n",
            "Step   1400: Ran 100 train steps in 44.06 secs\n",
            "Step   1400: train WeightedCategoryCrossEntropy |  7.02577114\n",
            "Step   1400: eval  WeightedCategoryCrossEntropy |  6.89442730\n",
            "Step   1400: eval      WeightedCategoryAccuracy |  0.10628019\n",
            "\n",
            "Step   1500: Ran 100 train steps in 45.53 secs\n",
            "Step   1500: train WeightedCategoryCrossEntropy |  6.94053125\n",
            "Step   1500: eval  WeightedCategoryCrossEntropy |  6.02038574\n",
            "Step   1500: eval      WeightedCategoryAccuracy |  0.14000000\n",
            "\n",
            "Step   1600: Ran 100 train steps in 44.49 secs\n",
            "Step   1600: train WeightedCategoryCrossEntropy |  6.99934149\n",
            "Step   1600: eval  WeightedCategoryCrossEntropy |  7.34409380\n",
            "Step   1600: eval      WeightedCategoryAccuracy |  0.09595960\n",
            "\n",
            "Step   1700: Ran 100 train steps in 44.51 secs\n",
            "Step   1700: train WeightedCategoryCrossEntropy |  7.00363493\n",
            "Step   1700: eval  WeightedCategoryCrossEntropy |  7.16865683\n",
            "Step   1700: eval      WeightedCategoryAccuracy |  0.11594203\n",
            "\n",
            "Step   1800: Ran 100 train steps in 46.89 secs\n",
            "Step   1800: train WeightedCategoryCrossEntropy |  6.95269680\n",
            "Step   1800: eval  WeightedCategoryCrossEntropy |  7.22740984\n",
            "Step   1800: eval      WeightedCategoryAccuracy |  0.10396039\n",
            "\n",
            "Step   1900: Ran 100 train steps in 44.16 secs\n",
            "Step   1900: train WeightedCategoryCrossEntropy |  6.89924717\n",
            "Step   1900: eval  WeightedCategoryCrossEntropy |  7.24631786\n",
            "Step   1900: eval      WeightedCategoryAccuracy |  0.10194175\n",
            "\n",
            "Step   2000: Ran 100 train steps in 44.34 secs\n",
            "Step   2000: train WeightedCategoryCrossEntropy |  6.87973022\n",
            "Step   2000: eval  WeightedCategoryCrossEntropy |  6.94071817\n",
            "Step   2000: eval      WeightedCategoryAccuracy |  0.11165049\n",
            "\n",
            "Step   2100: Ran 100 train steps in 44.31 secs\n",
            "Step   2100: train WeightedCategoryCrossEntropy |  6.88922024\n",
            "Step   2100: eval  WeightedCategoryCrossEntropy |  5.91659260\n",
            "Step   2100: eval      WeightedCategoryAccuracy |  0.12925170\n",
            "\n",
            "Step   2200: Ran 100 train steps in 45.09 secs\n",
            "Step   2200: train WeightedCategoryCrossEntropy |  6.86365080\n",
            "Step   2200: eval  WeightedCategoryCrossEntropy |  7.36692810\n",
            "Step   2200: eval      WeightedCategoryAccuracy |  0.12169313\n",
            "\n",
            "Step   2300: Ran 100 train steps in 46.98 secs\n",
            "Step   2300: train WeightedCategoryCrossEntropy |  6.80535364\n",
            "Step   2300: eval  WeightedCategoryCrossEntropy |  7.22541952\n",
            "Step   2300: eval      WeightedCategoryAccuracy |  0.12154697\n",
            "\n",
            "Step   2400: Ran 100 train steps in 44.53 secs\n",
            "Step   2400: train WeightedCategoryCrossEntropy |  6.76397133\n",
            "Step   2400: eval  WeightedCategoryCrossEntropy |  7.08752108\n",
            "Step   2400: eval      WeightedCategoryAccuracy |  0.12019231\n",
            "\n",
            "Step   2500: Ran 100 train steps in 44.59 secs\n",
            "Step   2500: train WeightedCategoryCrossEntropy |  6.74814796\n",
            "Step   2500: eval  WeightedCategoryCrossEntropy |  6.92052078\n",
            "Step   2500: eval      WeightedCategoryAccuracy |  0.12041885\n",
            "\n",
            "Step   2600: Ran 100 train steps in 44.73 secs\n",
            "Step   2600: train WeightedCategoryCrossEntropy |  6.84232569\n",
            "Step   2600: eval  WeightedCategoryCrossEntropy |  7.30097055\n",
            "Step   2600: eval      WeightedCategoryAccuracy |  0.08571429\n",
            "\n",
            "Step   2700: Ran 100 train steps in 44.32 secs\n",
            "Step   2700: train WeightedCategoryCrossEntropy |  6.79347038\n",
            "Step   2700: eval  WeightedCategoryCrossEntropy |  6.82370424\n",
            "Step   2700: eval      WeightedCategoryAccuracy |  0.11737090\n",
            "\n",
            "Step   2800: Ran 100 train steps in 44.62 secs\n",
            "Step   2800: train WeightedCategoryCrossEntropy |  6.73369408\n",
            "Step   2800: eval  WeightedCategoryCrossEntropy |  7.18787575\n",
            "Step   2800: eval      WeightedCategoryAccuracy |  0.12060301\n",
            "\n",
            "Step   2900: Ran 100 train steps in 44.28 secs\n",
            "Step   2900: train WeightedCategoryCrossEntropy |  6.71544075\n",
            "Step   2900: eval  WeightedCategoryCrossEntropy |  7.16090298\n",
            "Step   2900: eval      WeightedCategoryAccuracy |  0.10362695\n",
            "\n",
            "Step   3000: Ran 100 train steps in 44.33 secs\n",
            "Step   3000: train WeightedCategoryCrossEntropy |  6.75687075\n",
            "Step   3000: eval  WeightedCategoryCrossEntropy |  6.95898962\n",
            "Step   3000: eval      WeightedCategoryAccuracy |  0.11518325\n",
            "\n",
            "Step   3100: Ran 100 train steps in 66.98 secs\n",
            "Step   3100: train WeightedCategoryCrossEntropy |  6.80025625\n",
            "Step   3100: eval  WeightedCategoryCrossEntropy |  6.75250912\n",
            "Step   3100: eval      WeightedCategoryAccuracy |  0.10396039\n",
            "\n",
            "Step   3200: Ran 100 train steps in 45.03 secs\n",
            "Step   3200: train WeightedCategoryCrossEntropy |  6.78132439\n",
            "Step   3200: eval  WeightedCategoryCrossEntropy |  6.65073824\n",
            "Step   3200: eval      WeightedCategoryAccuracy |  0.10328639\n",
            "\n",
            "Step   3300: Ran 100 train steps in 44.27 secs\n",
            "Step   3300: train WeightedCategoryCrossEntropy |  6.82122135\n",
            "Step   3300: eval  WeightedCategoryCrossEntropy |  5.77767944\n",
            "Step   3300: eval      WeightedCategoryAccuracy |  0.19083969\n",
            "\n",
            "Step   3400: Ran 100 train steps in 44.17 secs\n",
            "Step   3400: train WeightedCategoryCrossEntropy |  6.86201096\n",
            "Step   3400: eval  WeightedCategoryCrossEntropy |  7.19156694\n",
            "Step   3400: eval      WeightedCategoryAccuracy |  0.09595960\n",
            "\n",
            "Step   3500: Ran 100 train steps in 46.31 secs\n",
            "Step   3500: train WeightedCategoryCrossEntropy |  6.87620974\n",
            "Step   3500: eval  WeightedCategoryCrossEntropy |  7.02337646\n",
            "Step   3500: eval      WeightedCategoryAccuracy |  0.09693877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f6c94a485f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -f /content/drive/MyDrive/Summarization/models/model.pkl.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_batch_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Summarization/models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_steps)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mtask_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_which_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mtask_changed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_index\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mprev_task_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_changed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;31m# optimizer_metrics and loss are replicated on self.n_devices, a few\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36m_run_one_step\u001b[0;34m(self, task_index, task_changed)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer_per_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    922\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m\"\"\"Returns one batch of labeled data: a tuple of input(s) plus label.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labeled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKrEBjmskeWa"
      },
      "source": [
        " <a name='4'></a>\n",
        " # Part 4:  Evaluation  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWoSzR5tkoAx"
      },
      "source": [
        "# Get the model architecture\n",
        "model = TransformerLM(mode='eval')\n",
        "\n",
        "# Load the pre-trained weights\n",
        "model.init_from_file('/content/drive/MyDrive/Summarization/models/model.pkl.gz', weights_only=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilM9C8P3RWRf"
      },
      "source": [
        "<a name='5'></a>\n",
        "# Part 5: Testing with your own input\n",
        "\n",
        "You are going to implement greedy decoding. This consists of two functions. The first one allows you to identify the next symbol. It gets the argmax of the output of your model and then returns that index. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD_bXRCpRWRg"
      },
      "source": [
        "def next_symbol(cur_output_tokens, model):\n",
        "    \"\"\"Returns the next symbol for a given sentence.\n",
        "\n",
        "    Args:\n",
        "        cur_output_tokens (list): tokenized sentence with EOS and PAD tokens at the end.\n",
        "        model (trax.layers.combinators.Serial): The transformer model.\n",
        "\n",
        "    Returns:\n",
        "        int: tokenized symbol.\n",
        "    \"\"\"\n",
        "    \n",
        "    # current output tokens length\n",
        "    token_length = len(cur_output_tokens)\n",
        "    # calculate the minimum power of 2 big enough to store token_length\n",
        "    # HINT: use np.ceil() and np.log2()\n",
        "    # add 1 to token_length so np.log2() doesn't receive 0 when token_length is 0\n",
        "    padded_length = 2**int(np.ceil(np.log2(token_length + 1)))\n",
        "\n",
        "    # Fill cur_output_tokens with 0's until it reaches padded_length\n",
        "    padded = cur_output_tokens + [0] * (padded_length - token_length)\n",
        "    padded_with_batch = np.array(padded)[None, :] # Don't replace this 'None'! This is a way of setting the batch dim\n",
        "\n",
        "    # model expects a tuple containing two padded tensors (with batch)\n",
        "    output, _ = model((padded_with_batch, padded_with_batch)) \n",
        "    # HINT: output has shape (1, padded_length, vocab_size)\n",
        "    # To get log_probs you need to index output with 0 in the first dim\n",
        "    # token_length in the second dim and all of the entries for the last dim.\n",
        "    \n",
        "    log_probs = output[0, token_length, :]\n",
        "    \n",
        "    return int(np.argmax(log_probs))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8P-JbVCFyT5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "615ccc12-4fb1-4afe-e043-bdf25213581f"
      },
      "source": [
        "# Test it out!\n",
        "sentence_test_nxt_symbl = \"I want to fly in the sky.\"\n",
        "detokenize([next_symbol(tokenize(sentence_test_nxt_symbl)+[0], model)])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Gov'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AwrQFglRWRj"
      },
      "source": [
        "<a name='5.1'></a>\n",
        "### 5.1 Greedy decoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HwIdimiN0k2"
      },
      "source": [
        "def greedy_decode(input_sentence, model):\n",
        "    \"\"\"Greedy decode function.\n",
        "\n",
        "    Args:\n",
        "        input_sentence (string): a sentence or article.\n",
        "        model (trax.layers.combinators.Serial): Transformer model.\n",
        "\n",
        "    Returns:\n",
        "        string: summary of the input.\n",
        "    \"\"\"\n",
        "\n",
        "    # Use tokenize()\n",
        "    cur_output_tokens = tokenize(input_sentence) + [0]\n",
        "    generated_output = [] \n",
        "    cur_output = 0 \n",
        "    EOS = 1 \n",
        "    \n",
        "    while cur_output != EOS:\n",
        "        # Get next symbol\n",
        "        cur_output = next_symbol(cur_output_tokens, model)\n",
        "        # Append next symbol to original sentence\n",
        "        cur_output_tokens.append(cur_output)\n",
        "        # Append next symbol to generated sentence\n",
        "        generated_output.append(cur_output)\n",
        "        print(detokenize(generated_output))\n",
        "    \n",
        "    return detokenize(generated_output)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kHuIDGW1sOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4e7d26-1acf-4417-d662-ebcea2e27eaf"
      },
      "source": [
        "# Test it out on a sentence!\n",
        "test_sentence = \"It was a sunny day when I went to the market to buy some flowers. But I only found roses, not tulips.\"\n",
        "print(wrapper.fill(test_sentence), '\\n')\n",
        "print(greedy_decode(test_sentence, model))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It was a sunny day when I went to the market to buy some flowers. But\n",
            "I only found roses, not tulips. \n",
            "\n",
            "Gov\n",
            "Gov39\n",
            "Gov39\n",
            "Gov39<EOS>\n",
            "Gov39<EOS>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYgX-mzjyUia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e343de0a-492c-458c-ccf3-909d99b33fc6"
      },
      "source": [
        "# Test it out with a whole article!\n",
        "article = \"It’s the posing craze sweeping the U.S. after being brought to fame by skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert Pujols - and even Republican politician Rick Perry. But now four students at Riverhead High School on Long Island, New York, have been suspended for dropping to a knee and taking up a prayer pose to mimic Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the ‘Tebowing’ craze was blocking the hallway and presenting a safety hazard to students. Scroll down for video. Banned: Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured left) were all suspended for one day by Riverhead High School on Long Island, New York, for their tribute to Broncos quarterback Tim Tebow. Issue: Four of the pupils were suspended for one day because they allegedly did not heed to warnings that the 'Tebowing' craze at the school was blocking the hallway and presenting a safety hazard to students.\"\n",
        "print(wrapper.fill(article), '\\n')\n",
        "print(greedy_decode(article, model))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It’s the posing craze sweeping the U.S. after being brought to fame by\n",
            "skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert\n",
            "Pujols - and even Republican politician Rick Perry. But now four\n",
            "students at Riverhead High School on Long Island, New York, have been\n",
            "suspended for dropping to a knee and taking up a prayer pose to mimic\n",
            "Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel,\n",
            "Tyler Carroll and Connor Carroll were all suspended for one day\n",
            "because the ‘Tebowing’ craze was blocking the hallway and presenting a\n",
            "safety hazard to students. Scroll down for video. Banned: Jordan\n",
            "Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured\n",
            "left) were all suspended for one day by Riverhead High School on Long\n",
            "Island, New York, for their tribute to Broncos quarterback Tim Tebow.\n",
            "Issue: Four of the pupils were suspended for one day because they\n",
            "allegedly did not heed to warnings that the 'Tebowing' craze at the\n",
            "school was blocking the hallway and presenting a safety hazard to\n",
            "students. \n",
            "\n",
            "&#\n",
            "&#39\n",
            "&#39;\n",
            "&#39;<EOS>\n",
            "&#39;<EOS>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}