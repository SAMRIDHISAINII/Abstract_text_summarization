# Abstractive summarization using Generative Pretrained Transformer (GPT-2)
Paper: [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf).
Dataset: https://www.kaggle.com/shashichander009/inshorts-news-data
